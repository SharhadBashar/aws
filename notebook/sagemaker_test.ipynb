{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4a19baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a52ecad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing following input: \n",
      "        CRIM   ZN  INDUS  CHAS   NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "173  0.09178  0.0   4.05   0.0  0.51  6.416  84.1  2.6463  5.0  296.0   \n",
      "\n",
      "     PTRATIO      B  LSTAT  \n",
      "173     16.6  395.5   9.04  \n",
      "<class 'list'>\n",
      "[28.99672362]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharhad/python_versions/3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/sharhad/python_versions/3.9/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "#Load data\n",
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['MEDV'] = boston.target \n",
    "\n",
    "#Split Model\n",
    "X = df.drop(['MEDV'], axis = 1) \n",
    "y = df['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)\n",
    "\n",
    "#Model Creation\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "with open('model.joblib', 'wb') as f:\n",
    "    joblib.dump(lm,f)\n",
    "\n",
    "\n",
    "with open('model.joblib', 'rb') as f:\n",
    "    predictor = joblib.load(f)\n",
    "\n",
    "print(\"Testing following input: \")\n",
    "print(X_test[0:1])\n",
    "sampInput = [[0.09178, 0.0, 4.05, 0.0, 0.51, 6.416, 84.1, 2.6463, 5.0, 296.0, 16.6, 395.5, 9.04]]\n",
    "print(type(sampInput))\n",
    "print(predictor.predict(sampInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa89d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'day fire starter people fire light ðŸ”¥ minister gospel commitment spreading god grace power'\n",
    "# output = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "918a8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl_model(path):\n",
    "    return pkl.load(open(path, 'rb'))\n",
    "\n",
    "def convert_pkl_joblib(model, language = 'en'):\n",
    "    with open(f'../models/model_{language}.joblib', 'wb') as file:\n",
    "        joblib.dump(model, file)\n",
    "    print('Model converted')\n",
    "    \n",
    "def load_joblib_model(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        model = joblib.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "117f05f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharhad/python_versions/3.9/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.2.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/sharhad/python_versions/3.9/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/sharhad/python_versions/3.9/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/sharhad/python_versions/3.9/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/sharhad/python_versions/3.9/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 1.2.0 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pkl model prediction: 8\n",
      "Model converted\n",
      "joblib model prediction: 8\n"
     ]
    }
   ],
   "source": [
    "model_pkl = load_pkl_model('../models/model.pkl')\n",
    "print('pkl model prediction:', model_pkl.predict([text])[0])\n",
    "convert_pkl_joblib(model_pkl)\n",
    "model_joblib = load_joblib_model('../models/model_en.joblib')\n",
    "print('joblib model prediction:', model_joblib.predict([text])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b947e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deserialize fitted model\n",
    "\"\"\"\n",
    "def model_fn(model_dir, language = 'en'):\n",
    "    model = joblib.load(os.path.join(model_dir, f'model_{language}.joblib'))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body):\n",
    "    if (type(request_body) == str):\n",
    "        return [request_body]\n",
    "    else:\n",
    "        raise ValueError('This model only supports string inputs')\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)[0] #could be bug here\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\n",
    "\"\"\"\n",
    "def output_fn(prediction):\n",
    "    return int(prediction[0]) #could be bug here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d64d0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "import tarfile\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39dd1673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bundle(language = 'en'):\n",
    "    bashCommand = 'tar -cvpzf model_en.tar.gz model_en.joblib inference.py'\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout = subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    print('Output:', output)  \n",
    "    if error:\n",
    "        print('Error:', error)\n",
    "\n",
    "def upload(language = 'en', default_bucket = 'ts-contextual-web-api'):\n",
    "    boto_session = boto3.session.Session()\n",
    "    s3 = boto_session.resource('s3')\n",
    "    boto_session = boto3.session.Session()\n",
    "    response = s3.meta.client.upload_file('model_en.tar.gz', default_bucket, 'model_en.tar.gz')\n",
    "    print('Response:', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d13d09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a model_en.joblib\n",
      "a inference.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: b''\n",
      "Response: None\n",
      "dev-bluebox\n",
      "ops-vault-eu-aws-state\n",
      "ops-vault-prd\n",
      "ops-vault-stg\n",
      "sc-eu-aws-state\n",
      "tf-poc-aws-state\n",
      "tf-poceu-aws-state\n",
      "ts-contextual-web-api\n",
      "ts-fill-in-blanks\n",
      "ts-podcast-iq\n",
      "ts-ryan\n",
      "ts-temp-bucket\n",
      "ts-transcription\n",
      "ts-veeam-storage\n",
      "ts-whisper\n",
      "tsadobe\n",
      "tsdigiseg\n",
      "tsivt\n",
      "tsliveramp\n",
      "tsppiq\n",
      "tstruoptik\n"
     ]
    }
   ],
   "source": [
    "bundle()\n",
    "upload()\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.list_buckets()\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffa13a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: sklearn-test2023-05-05-16-55-39\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:052845409385:model/sklearn-test2023-05-05-16-55-39\n"
     ]
    }
   ],
   "source": [
    "default_bucket = 'ts-contextual-web-api'\n",
    "client = boto3.client(service_name = 'sagemaker')\n",
    "runtime = boto3.client(service_name = 'sagemaker-runtime')\n",
    "model_artifacts = f's3://{default_bucket}/model_en.tar.gz'\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework = 'sklearn',\n",
    "    region = 'us-east-1',\n",
    "    version = '0.23-1',\n",
    "    py_version = 'py3',\n",
    "    instance_type = 'ml.m5.2xlarge'\n",
    ")\n",
    "\n",
    "model_name = 'sklearn-test' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print('Model name:', model_name)\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = model_name,\n",
    "    Containers = [\n",
    "        {\n",
    "            'Image': image_uri,\n",
    "            'Mode': 'SingleModel',\n",
    "            'ModelDataUrl': model_artifacts,\n",
    "            'Environment': {'SAGEMAKER_SUBMIT_DIRECTORY': model_artifacts,\n",
    "                           'SAGEMAKER_PROGRAM': 'inference.py'} \n",
    "        }\n",
    "    ],\n",
    "    ExecutionRoleArn = 'arn:aws:iam::052845409385:role/AmazonSageMaker-ExecutionRole'\n",
    ")\n",
    "print('Model Arn: ' + create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91cc1668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Configuration Arn: arn:aws:sagemaker:us-east-1:052845409385:endpoint-config/sklearn-epc2023-05-05-16-55-44\n"
     ]
    }
   ],
   "source": [
    "sklearn_epc_name = 'sklearn-epc' + strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName = sklearn_epc_name,\n",
    "    ProductionVariants = [\n",
    "        {\n",
    "            'VariantName': 'sklearnvariant',\n",
    "            'ModelName': model_name,\n",
    "            'InstanceType': 'ml.c5.4xlarge',\n",
    "            'InitialInstanceCount': 1\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print('Endpoint Configuration Arn: ' + endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f009a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:052845409385:endpoint/sklearn-local-ep2023-05-05-16-55-49\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Failed\n",
      "{'EndpointName': 'sklearn-local-ep2023-05-05-16-55-49', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:052845409385:endpoint/sklearn-local-ep2023-05-05-16-55-49', 'EndpointConfigName': 'sklearn-epc2023-05-05-16-55-44', 'EndpointStatus': 'Failed', 'FailureReason': 'The primary container for production variant sklearnvariant did not pass the ping health check. Please check CloudWatch logs for this endpoint.', 'CreationTime': datetime.datetime(2023, 5, 5, 12, 55, 49, 815000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2023, 5, 5, 13, 19, 20, 247000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '0ba012e8-711f-48f0-b51d-805b621bac1e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '0ba012e8-711f-48f0-b51d-805b621bac1e', 'content-type': 'application/x-amz-json-1.1', 'content-length': '466', 'date': 'Fri, 05 May 2023 17:21:29 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = 'sklearn-local-ep' + strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName = endpoint_name,\n",
    "    EndpointConfigName = sklearn_epc_name,\n",
    ")\n",
    "print('Endpoint Arn: ' + create_endpoint_response['EndpointArn'])\n",
    "\n",
    "\n",
    "#Monitor creation\n",
    "describe_endpoint_response = client.describe_endpoint(EndpointName = endpoint_name)\n",
    "while describe_endpoint_response['EndpointStatus'] == 'Creating':\n",
    "    describe_endpoint_response = client.describe_endpoint(EndpointName = endpoint_name)\n",
    "    print(describe_endpoint_response['EndpointStatus'])\n",
    "    time.sleep(150)\n",
    "print(describe_endpoint_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "content_type = str\n",
    "# request_body = {'Input': [[0.09178, 0.0, 4.05, 0.0, 0.51, 6.416, 84.1, 2.6463, 5.0, 296.0, 16.6, 395.5, 9.04]]}\n",
    "# data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(text)\n",
    "# endpoint_name = 'enter endpoint name here'\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName = endpoint_name,\n",
    "    ContentType = content_type,\n",
    "    Body = payload)\n",
    "result = json.loads(response['Body'].read().decode())['Output']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
